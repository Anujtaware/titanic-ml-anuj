# Titanic â€“ Machine Learning from Disaster ğŸš¢

**Author:** Anuj Taware  
**Platform:** Kaggle  

---

## ğŸ“Œ Project Overview
This project solves the classic Kaggle competition **Titanic â€“ Machine Learning from Disaster**.  
The goal is to predict passenger survival using supervised machine learning techniques and demonstrate the complete ML workflow.

---

## ğŸ“Š Dataset
- Source: Kaggle Titanic Dataset
- Training samples: 891
- Test samples: 418
- Target variable: `Survived` (0 = No, 1 = Yes)

---

## âš™ï¸ Machine Learning Workflow
1. Data loading and inspection  
2. Handling missing values (Age, Embarked)  
3. Feature encoding (Sex, Embarked)  
4. Feature selection  
5. Trainâ€“test split  
6. Model training  
7. Prediction and evaluation  

---

## ğŸ§  Model Used
- Logistic Regression / Decision Tree (baseline model)
- Focus on generalization over overfitting

---

## ğŸ¯ ML Concepts from Syllabus
- Training vs Generalization Error  
- Biasâ€“Variance Trade-off  
- Feature Engineering  
- Baseline Models  
- Model Evaluation using Accuracy  

---

## ğŸ† Kaggle Results
- **Public Score:** 0.77511  
- **Leaderboard Rank:** 7925  

---

## ğŸ”— Links
- **Kaggle Notebook:**  
  https://www.kaggle.com/code/anujtaware/getting-started-with-titanic  

- **Kaggle Competition:**  
  https://www.kaggle.com/competitions/titanic  

- **GitHub Repository:**  
  https://github.com/Anujtaware/titanic-ml-anuj  

---

## ğŸ“ Repository Contents
- `getting-started-with-titanic.ipynb` â€“ Complete notebook  
- `submission.csv` â€“ Kaggle submission file  
- Screenshots â€“ Kaggle submission and rank proof  

---

## âœ… Conclusion
This project demonstrates a complete end-to-end machine learning pipeline and aligns with core ML syllabus topics such as model training, generalization, and evaluation.
